import { createPool } from "mysql2/promise";
import dotenv from "dotenv";
import * as fs from "fs";
import path from "path";

dotenv.config(); // Load biáº¿n mÃ´i trÆ°á»ng tá»« .env

// ğŸ”Œ Káº¿t ná»‘i TiDB vá»›i Connection Pool
const pool = createPool({
    host: process.env.TIDB_HOST || '127.0.0.1',
    port: process.env.TIDB_PORT || 4000,
    user: process.env.TIDB_USER || 'root',
    password: process.env.TIDB_PASSWORD || '',
    database: process.env.TIDB_DATABASE || 'mydb',
    ssl: process.env.TIDB_ENABLE_SSL === 'true' ? {
        minVersion: 'TLSv1.2',
        ca: process.env.TIDB_CA_PATH ? fs.readFileSync(process.env.TIDB_CA_PATH) : undefined
    } : null,
    multipleStatements: true,
    connectionLimit: 10 // Giá»›i háº¡n sá»‘ connection tá»‘i Ä‘a
});

// ğŸ“‚ ÄÆ°á»ng dáº«n thÆ° má»¥c chá»©a file CSV Ä‘Ã£ chia theo partition
const partitionFolder = path.resolve("F:/Intern NodeJS/internNodeJs/output");

// ğŸ”¢ Sá»‘ lÆ°á»£ng partition (Ä‘Ã£ táº¡o trong MySQL/TiDB)
const numPartitions = 5;

// ğŸ“Œ HÃ m nháº­p dá»¯ liá»‡u tá»« file CSV vÃ o TiDB
async function importCSVPart(threadId, partitionIndex) {
    const conn = await pool.getConnection();
    const startTime = Date.now();

    // ğŸ“‚ File CSV cá»§a partition
    const csvFilePath = path.join(partitionFolder, `users_partition_${partitionIndex}.csv`);

    // Kiá»ƒm tra file cÃ³ tá»“n táº¡i khÃ´ng
    if (!fs.existsSync(csvFilePath)) {
        console.error(`âŒ File ${csvFilePath} khÃ´ng tá»“n táº¡i!`);
        return;
    }

    try {
        await conn.beginTransaction();
        console.log(`ğŸš€ Thread ${threadId} importing file ${csvFilePath}...`);

        await conn.query("SET GLOBAL local_infile = 1;");

        // âœ… Cháº¡y `LOAD DATA LOCAL INFILE` Ä‘á»ƒ nháº­p file CSV cá»§a partition
        const query = `
            LOAD DATA LOCAL INFILE ? 
            INTO TABLE users 
            FIELDS TERMINATED BY ',' 
            LINES TERMINATED BY '\n' 
            IGNORE 1 LINES 
            (id, name, email, created_at);
        `;

        await conn.query({
            sql: query,
            values: [csvFilePath],
            infileStreamFactory: () => fs.createReadStream(csvFilePath) // Stream file Ä‘á»ƒ trÃ¡nh tá»‘n RAM
        });

        await conn.commit();
        const endTime = Date.now();
        console.log(`âœ… Thread ${threadId} completed file ${csvFilePath} in ${(endTime - startTime) / 1000}s`);
    } catch (error) {
        await conn.rollback();
        console.error(`âŒ Thread ${threadId} failed!`, error.message);
    } finally {
        conn.release();
    }
}

// ğŸ“Œ HÃ m cháº¡y 5 luá»“ng song song Ä‘á»ƒ nháº­p dá»¯ liá»‡u tá»« 5 file CSV
async function runMultiThreadImport() {
    const globalStartTime = Date.now();
    const tasks = [];

    for (let i = 0; i < numPartitions; i++) {
        tasks.push(importCSVPart(i, i)); // Má»—i thread xá»­ lÃ½ 1 file CSV
    }

    await Promise.all(tasks);

    const globalEndTime = Date.now();
    console.log(`ğŸ All partitions imported in ${(globalEndTime - globalStartTime) / 1000}s`);

    
}

// ğŸ Cháº¡y import vá»›i 5 file CSV
runMultiThreadImport().catch(console.error);
